{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZDSlGxlyEF",
        "outputId": "01bbbf6b-4d63-4530-cc2f-21ddc7170667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between Document 1 and Document 2: 0.1010\n",
            "Similarity between Document 2 and Document 3: 0.0390\n",
            "Similarity between Document 1 and Document 3: 0.0325\n",
            "Similarity between Document 2 and Document 4: 0.0304\n",
            "Similarity between Document 3 and Document 4: 0.0260\n",
            "Similarity between Document 1 and Document 4: 0.0253\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "# Function to tokenize and preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize and convert to lowercase\n",
        "    words = re.findall(r'\\w+', text.lower())\n",
        "    return words\n",
        "\n",
        "# Function to calculate the term frequency (TF) for each word in a document\n",
        "def calculate_tf(text):\n",
        "    word_count = {}\n",
        "    words = preprocess_text(text)\n",
        "    for word in words:\n",
        "        word_count[word] = word_count.get(word, 0) + 1\n",
        "    return word_count\n",
        "\n",
        "# Function to calculate the inverse document frequency (IDF) for a set of documents\n",
        "def calculate_idf(documents):\n",
        "    idf = {}\n",
        "    total_documents = len(documents)\n",
        "    for document in documents:\n",
        "        words = set(preprocess_text(document))\n",
        "        for word in words:\n",
        "            idf[word] = idf.get(word, 0) + 1\n",
        "\n",
        "    for word, count in idf.items():\n",
        "        idf[word] = math.log(total_documents / (count + 1))\n",
        "\n",
        "    return idf\n",
        "\n",
        "# Function to calculate the cosine similarity between two documents\n",
        "def calculate_cosine_similarity(doc1, doc2, idf):\n",
        "    tf1 = calculate_tf(doc1)\n",
        "    tf2 = calculate_tf(doc2)\n",
        "\n",
        "    # Calculate the dot product\n",
        "    dot_product = 0\n",
        "    for word in set(tf1.keys()) & set(tf2.keys()):\n",
        "        dot_product += tf1[word] * tf2[word] * idf[word] ** 2\n",
        "\n",
        "    # Calculate the magnitude of vectors\n",
        "    magnitude1 = math.sqrt(sum((tf1[word] * idf[word]) ** 2 for word in tf1))\n",
        "    magnitude2 = math.sqrt(sum((tf2[word] * idf[word]) ** 2 for word in tf2))\n",
        "\n",
        "    if magnitude1 == 0 or magnitude2 == 0:\n",
        "        return 0  # Avoid division by zero\n",
        "\n",
        "    return dot_product / (magnitude1 * magnitude2)\n",
        "\n",
        "# Example documents\n",
        "document1 = \"This is the first document.\"\n",
        "document2 = \"Here is another document.\"\n",
        "document3 = \"A third example document.\"\n",
        "document4 = \"One more document for good measure.\"\n",
        "\n",
        "documents = [document1, document2, document3, document4]\n",
        "\n",
        "# Calculate IDF values\n",
        "idf = calculate_idf(documents)\n",
        "\n",
        "# Calculate and print the cosine similarity between all pairs of documents\n",
        "similarities = []\n",
        "for i in range(len(documents)):\n",
        "    for j in range(i + 1, len(documents)):\n",
        "        similarity = calculate_cosine_similarity(documents[i], documents[j], idf)\n",
        "        similarities.append((i, j, similarity))\n",
        "\n",
        "similarities.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "for i, j, similarity in similarities:\n",
        "    print(f\"Similarity between Document {i+1} and Document {j+1}: {similarity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.spatial.distance as dist\n",
        "dist.chebyshev([1,0,2,3,2,4], [2,1,0,2,1,0])"
      ],
      "metadata": {
        "id": "Q3IOGj-_osxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be434a8b-4e19-41a9-cc08-1e267fb31d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLF7Mmgm4NT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}