{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3089a8",
      "metadata": {
        "id": "0d3089a8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48659a82",
      "metadata": {
        "id": "48659a82"
      },
      "outputs": [],
      "source": [
        "def adaboost(X,y,weak_classifiers=5):\n",
        "    n = len(X)\n",
        "    wt = np.full(n,(1/n))\n",
        "    models = []\n",
        "    alphas = []\n",
        "\n",
        "    print(\"Step 0\")\n",
        "    print(wt)\n",
        "\n",
        "\n",
        "    for i in range(weak_classifiers):\n",
        "        model = LogisticRegression()\n",
        "        #model = GaussianNB()\n",
        "        model.fit(X,y, sample_weight=wt)\n",
        "        predictions = model.predict(X)\n",
        "\n",
        "        #print(predictions!=y)\n",
        "\n",
        "        weighted_error = np.sum(wt*(y!=predictions))\n",
        "\n",
        "        alpha = 0.5*np.log((1-weighted_error)/(weighted_error)) # Avoid division by zero\n",
        "        alphas.append(alpha)\n",
        "\n",
        "        # Wt update\n",
        "        wt *= np.exp(-alpha*(y!=predictions))\n",
        "        wt /=np.sum(wt)\n",
        "\n",
        "        models.append(model)\n",
        "        print(\"Step \",i+1)\n",
        "        print(wt)\n",
        "\n",
        "    return models, alphas\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f196b430",
      "metadata": {
        "id": "f196b430"
      },
      "outputs": [],
      "source": [
        "def predict(X, models, alphas):\n",
        "    predictions = np.zeros(len(X))\n",
        "    for alpha, model in zip(alphas, models):\n",
        "        predictions += alpha* model.predict(X)\n",
        "    return np.sign(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94b1a28",
      "metadata": {
        "id": "c94b1a28"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=100, n_features=4, n_classes=2, n_clusters_per_class=1, class_sep=0.5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0c40d12",
      "metadata": {
        "id": "b0c40d12",
        "outputId": "e1713a46-24db-4835-8d77-89dbc51e98b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0\n",
            "[0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125\n",
            " 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125 0.0125]\n",
            "Step  1\n",
            "[0.01394726 0.007515   0.01394726 0.01394726 0.01394726 0.007515\n",
            " 0.01394726 0.007515   0.007515   0.01394726 0.01394726 0.01394726\n",
            " 0.01394726 0.01394726 0.01394726 0.01394726 0.01394726 0.01394726\n",
            " 0.007515   0.007515   0.01394726 0.007515   0.01394726 0.01394726\n",
            " 0.007515   0.01394726 0.01394726 0.01394726 0.01394726 0.007515\n",
            " 0.01394726 0.01394726 0.007515   0.01394726 0.01394726 0.01394726\n",
            " 0.01394726 0.01394726 0.01394726 0.007515   0.01394726 0.007515\n",
            " 0.01394726 0.01394726 0.01394726 0.01394726 0.01394726 0.01394726\n",
            " 0.01394726 0.007515   0.01394726 0.01394726 0.01394726 0.007515\n",
            " 0.01394726 0.01394726 0.007515   0.007515   0.01394726 0.01394726\n",
            " 0.007515   0.01394726 0.01394726 0.01394726 0.01394726 0.01394726\n",
            " 0.01394726 0.01394726 0.01394726 0.007515   0.01394726 0.01394726\n",
            " 0.01394726 0.01394726 0.01394726 0.01394726 0.01394726 0.01394726\n",
            " 0.01394726 0.01394726]\n",
            "Step  2\n",
            "[0.01522835 0.00333398 0.01522835 0.01522835 0.01522835 0.00333398\n",
            " 0.01522835 0.00333398 0.00333398 0.01522835 0.01522835 0.01522835\n",
            " 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835\n",
            " 0.00333398 0.00333398 0.01522835 0.00333398 0.01522835 0.01522835\n",
            " 0.00333398 0.01522835 0.01522835 0.01522835 0.01522835 0.00333398\n",
            " 0.01522835 0.01522835 0.00333398 0.01522835 0.01522835 0.01522835\n",
            " 0.01522835 0.01522835 0.01522835 0.00333398 0.01522835 0.00820528\n",
            " 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835\n",
            " 0.01522835 0.00333398 0.01522835 0.01522835 0.01522835 0.00333398\n",
            " 0.01522835 0.01522835 0.00333398 0.00333398 0.01522835 0.01522835\n",
            " 0.00333398 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835\n",
            " 0.01522835 0.01522835 0.01522835 0.00333398 0.01522835 0.01522835\n",
            " 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835 0.01522835\n",
            " 0.01522835 0.0061876 ]\n",
            "Step  3\n",
            "[0.01675301 0.00161737 0.01675301 0.01675301 0.01675301 0.00366778\n",
            " 0.01675301 0.00161737 0.00161737 0.01675301 0.01675301 0.00738752\n",
            " 0.01675301 0.01675301 0.01675301 0.00738752 0.01675301 0.01675301\n",
            " 0.00366778 0.00161737 0.01675301 0.00161737 0.01675301 0.01675301\n",
            " 0.00161737 0.01675301 0.01675301 0.01675301 0.01675301 0.00161737\n",
            " 0.01675301 0.01675301 0.00161737 0.01675301 0.01675301 0.01675301\n",
            " 0.01675301 0.01675301 0.01675301 0.00161737 0.01675301 0.00902679\n",
            " 0.01675301 0.01675301 0.01675301 0.00738752 0.01675301 0.01675301\n",
            " 0.01675301 0.00161737 0.01675301 0.01675301 0.00738752 0.00161737\n",
            " 0.01675301 0.01675301 0.00161737 0.00161737 0.01675301 0.01675301\n",
            " 0.00161737 0.00738752 0.01675301 0.01675301 0.01675301 0.01675301\n",
            " 0.01675301 0.01675301 0.01675301 0.00161737 0.01675301 0.01675301\n",
            " 0.00738752 0.01675301 0.01675301 0.01675301 0.00738752 0.01675301\n",
            " 0.01675301 0.00300171]\n",
            "Step  4\n",
            "[0.01826434 0.00070522 0.01826434 0.01826434 0.01826434 0.00399865\n",
            " 0.01826434 0.00070522 0.00176327 0.00730478 0.00730478 0.00322117\n",
            " 0.01826434 0.01826434 0.01826434 0.00322117 0.00730478 0.01826434\n",
            " 0.00399865 0.00070522 0.01826434 0.00176327 0.01826434 0.01826434\n",
            " 0.00176327 0.01826434 0.01826434 0.01826434 0.01826434 0.00070522\n",
            " 0.01826434 0.01826434 0.00070522 0.01826434 0.01826434 0.01826434\n",
            " 0.01826434 0.01826434 0.01826434 0.00176327 0.01826434 0.00984112\n",
            " 0.01826434 0.01826434 0.01826434 0.00322117 0.01826434 0.01826434\n",
            " 0.01826434 0.00070522 0.01826434 0.01826434 0.00322117 0.00070522\n",
            " 0.01826434 0.01826434 0.00070522 0.00070522 0.01826434 0.01826434\n",
            " 0.00070522 0.00322117 0.01826434 0.01826434 0.01826434 0.01826434\n",
            " 0.01826434 0.00730478 0.01826434 0.00176327 0.01826434 0.01826434\n",
            " 0.00322117 0.01826434 0.01826434 0.01826434 0.00322117 0.01826434\n",
            " 0.01826434 0.00130883]\n",
            "Step  5\n",
            "[0.02031885 0.00039991 0.02031885 0.02031885 0.02031885 0.00444845\n",
            " 0.02031885 0.00039991 0.00196162 0.00414236 0.00414236 0.00182665\n",
            " 0.02031885 0.01035726 0.02031885 0.00182665 0.00414236 0.02031885\n",
            " 0.00444845 0.00039991 0.01035726 0.00196162 0.02031885 0.01035726\n",
            " 0.00196162 0.02031885 0.02031885 0.02031885 0.02031885 0.00039991\n",
            " 0.02031885 0.02031885 0.00039991 0.02031885 0.02031885 0.02031885\n",
            " 0.02031885 0.02031885 0.01035726 0.00196162 0.02031885 0.01094812\n",
            " 0.02031885 0.02031885 0.02031885 0.00182665 0.02031885 0.01035726\n",
            " 0.02031885 0.00039991 0.02031885 0.01035726 0.00182665 0.00039991\n",
            " 0.02031885 0.01035726 0.00039991 0.00039991 0.02031885 0.01035726\n",
            " 0.00039991 0.00182665 0.02031885 0.02031885 0.02031885 0.02031885\n",
            " 0.02031885 0.00414236 0.02031885 0.00196162 0.02031885 0.02031885\n",
            " 0.00182665 0.02031885 0.02031885 0.02031885 0.00182665 0.02031885\n",
            " 0.02031885 0.0007422 ]\n"
          ]
        }
      ],
      "source": [
        "models, alphas = adaboost(X_train, y_train, weak_classifiers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09de2e1a",
      "metadata": {
        "id": "09de2e1a"
      },
      "outputs": [],
      "source": [
        "y_pred = predict(X_test, models, alphas)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e89d58f",
      "metadata": {
        "id": "2e89d58f",
        "outputId": "64406f79-6a90-46cb-8b87-04a2390a6c02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.6183813135744635,\n",
              " 0.9006112210844465,\n",
              " 0.8187858609221778,\n",
              " 0.9164208515328521,\n",
              " 0.673861095318906]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alphas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a51134f8",
      "metadata": {
        "id": "a51134f8",
        "outputId": "2baf8a13-9b55-4fb4-97b3-e5fa341ce32f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7735f42",
      "metadata": {
        "id": "b7735f42",
        "outputId": "e38aa725-ba1c-40fa-92a9-2dee2ef85bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.78        11\n",
            "           1       0.75      0.67      0.71         9\n",
            "\n",
            "    accuracy                           0.75        20\n",
            "   macro avg       0.75      0.74      0.74        20\n",
            "weighted avg       0.75      0.75      0.75        20\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400c5295",
      "metadata": {
        "id": "400c5295"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef96918",
      "metadata": {
        "id": "7ef96918"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ef13f1",
      "metadata": {
        "id": "44ef13f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e1cf4e",
      "metadata": {
        "id": "03e1cf4e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}