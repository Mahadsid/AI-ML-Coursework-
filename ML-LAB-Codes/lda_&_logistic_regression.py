# -*- coding: utf-8 -*-
"""LDA & Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXaYZgy7bYnCmNE6-XtvoBXspSSZ4bsp
"""

import numpy as np
import matplotlib.pyplot as plt

def train_logistic_regression(X, y, learning_rate=0.1, n_iters=1000):
    # Initialize weights and bias
    weights = np.zeros(X.shape[1])
    bias = 0
    losses = []

    # Train logistic regression model
    for _ in range(n_iters):
        # Forward pass
        linear_model = np.dot(X, weights) + bias
        y_predicted = 1 / (1 + np.exp(-linear_model))  # sigmoidal func

        # Compute loss
        loss = -np.mean(y * np.log(y_predicted) + (1 - y) * np.log(1 - y_predicted))
        losses.append(loss)

        # Backward pass
        dw = (1 / len(X)) * np.dot(X.T, (y_predicted - y))
        db = (1 / len(X)) * np.sum(y_predicted - y)

        # Update weights and bias
        weights -= learning_rate * dw
        bias -= learning_rate * db

    return weights, bias, losses

# Generate random dataset
np.random.seed(0)  # for reproducibility
X = np.random.rand(30, 2)
y = np.random.randint(0, 2, size=30)

# Train logistic regression model
weights, bias, losses = train_logistic_regression(X, y)

# Print dataset
print("Dataset:")
for i in range(len(X)):
    print(f"Sample {i+1}: Features={X[i]}, Label={y[i]}")


# Plot loss graph
plt.figure(figsize=(8, 6))
plt.plot(losses)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Loss During Training')
plt.show()

# Predict labels
y_predicted = 1 / (1 + np.exp(-(np.dot(X, weights) + bias)))
y_predicted_cls = np.round(y_predicted)

# Calculate accuracy
accuracy = np.mean(y_predicted_cls == y) * 100
print(f"Accuracy: {accuracy:.2f}%")

"""LDA"""

import numpy as np


class LDA:
    def __init__(self, n_components):
        self.n_components = n_components
        self.linear_discriminants = None

    def fit(self, X, y):
        n_features = X.shape[1]
        class_labels = np.unique(y)

        # Within class scatter matrix:
        # SW = sum((X_c - mean_X_c)^2 )

        # Between class scatter:
        # SB = sum( n_c * (mean_X_c - mean_overall)^2 )

        mean_overall = np.mean(X, axis=0)
        SW = np.zeros((n_features, n_features))
        SB = np.zeros((n_features, n_features))
        for c in class_labels:
            X_c = X[y == c]
            mean_c = np.mean(X_c, axis=0)
            # (4, n_c) * (n_c, 4) = (4,4) -> transpose
            SW += (X_c - mean_c).T.dot((X_c - mean_c))

            # (4, 1) * (1, 4) = (4,4) -> reshape
            n_c = X_c.shape[0]
            mean_diff = (mean_c - mean_overall).reshape(n_features, 1)
            SB += n_c * (mean_diff).dot(mean_diff.T)

        # Determine SW^-1 * SB
        A = np.linalg.inv(SW).dot(SB)
        # Get eigenvalues and eigenvectors of SW^-1 * SB
        eigenvalues, eigenvectors = np.linalg.eig(A)
        # -> eigenvector v = [:,i] column vector, transpose for easier calculations
        # sort eigenvalues high to low
        eigenvectors = eigenvectors.T
        idxs = np.argsort(abs(eigenvalues))[::-1]
        eigenvalues = eigenvalues[idxs]
        eigenvectors = eigenvectors[idxs]
        # store first n eigenvectors
        self.linear_discriminants = eigenvectors[0 : self.n_components]

    def transform(self, X):
        # project data
        return np.dot(X, self.linear_discriminants.T)


# Testing
if __name__ == "__main__":
    # Imports
    import matplotlib.pyplot as plt
    from sklearn import datasets

    data = datasets.load_iris()
    X, y = data.data, data.target

    # Project the data onto the 2 primary linear discriminants
    lda = LDA(2)
    lda.fit(X, y)
    X_projected = lda.transform(X)

    print("Shape of X:", X.shape)
    print("Shape of transformed X:", X_projected.shape)

    x1, x2 = X_projected[:, 0], X_projected[:, 1]

    plt.scatter(
        x1, x2, c=y, edgecolor="none", alpha=0.8, cmap=plt.cm.get_cmap("viridis", 3)
    )

    plt.xlabel("Linear Discriminant 1")
    plt.ylabel("Linear Discriminant 2")
    plt.colorbar()
    plt.show()