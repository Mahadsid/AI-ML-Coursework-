{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U91fzv4PChL3",
        "outputId": "4f6b77ce-ab1a-4cfd-8146-36b990a5bf00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of rows for matrix 1: 4\n",
            "Enter the number of columns for matrix 1: 1\n",
            "Enter element at position (0, 0): 1\n",
            "Enter element at position (1, 0): 2\n",
            "Enter element at position (2, 0): 3\n",
            "Enter element at position (3, 0): 4\n",
            "[1]\n",
            "[2]\n",
            "[3]\n",
            "[4]\n"
          ]
        }
      ],
      "source": [
        "rows1 = int(input(\"Enter the number of rows for matrix 1: \"))\n",
        "cols1 = int(input(\"Enter the number of columns for matrix 1: \"))\n",
        "inputs = []\n",
        "for i in range(rows1):\n",
        "    row = []\n",
        "    for j in range(cols1):\n",
        "        element = int(input(\"Enter element at position ({}, {}): \".format(i, j)))\n",
        "        row.append(element)\n",
        "    inputs.append(row)\n",
        "\n",
        "for row in inputs:\n",
        "    print(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of sigmoid\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Initialize weights and bias\n",
        "def initialize_weights(input_size):\n",
        "    return np.random.uniform(-1, 1, (input_size, 1))\n",
        "\n",
        "def initialize_bias():\n",
        "    return np.random.uniform(-1, 1)\n",
        "\n",
        "# Forward pass with bias\n",
        "def forward(inputs, weights, bias):\n",
        "    return sigmoid(np.dot(inputs, weights) + bias)\n",
        "\n",
        "# Training function with bias adjustment\n",
        "def train(training_inputs, training_outputs, training_iterations, weights, bias):\n",
        "\n",
        "    for iteration in range(training_iterations):\n",
        "        output = forward(training_inputs, weights, bias)\n",
        "        error = training_outputs - output\n",
        "\n",
        "        adjustments = np.dot(training_inputs.T, error * sigmoid_derivative(output))\n",
        "        weights += adjustments\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Training data\n",
        "training_inputs = np.array([[0, 0, 1],\n",
        "                            [1, 1, 1],\n",
        "                            [1, 0, 1],\n",
        "                            [0, 1, 1]])\n",
        "\n",
        "training_outputs = np.array([[0, 1, 1, 0]]).T\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = initialize_weights(3)\n",
        "bias = initialize_bias()\n",
        "\n",
        "print(\"Initial weights:\")\n",
        "print(weights)\n",
        "print(\"Initial bias:\")\n",
        "print(bias)\n",
        "\n",
        "# Train the neural network\n",
        "trained_weights, trained_bias = train(training_inputs, training_outputs, 10000, weights, bias)\n",
        "\n",
        "print(\"Trained weights after training:\")\n",
        "print(trained_weights)\n",
        "\n",
        "new_input = np.array([1, 0, 0])\n",
        "output = forward(new_input, trained_weights, trained_bias)\n",
        "print(\"Prediction for new input [1, 0, 0]:\")\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hlKBk6TUi7f",
        "outputId": "8d0bf358-a0fe-4f3a-e46b-78a0695601bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights:\n",
            "[[ 0.95250972]\n",
            " [-0.33258866]\n",
            " [ 0.79324318]]\n",
            "Initial bias:\n",
            "-0.9504991451342271\n",
            "Trained weights after training:\n",
            "[[ 9.67332988]\n",
            " [-0.20858297]\n",
            " [-3.67886503]]\n",
            "Prediction for new input [1, 0, 0]:\n",
            "[0.9998372]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uI7YJgbmbZWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(inputs, num_filters):\n",
        "\n",
        "\t# Convolution with 3x3 filter followed by ReLU activation\n",
        "\tx = tf.keras.layers.Conv2D(num_filters,\n",
        "\t\t\t\t\t\t\t3,\n",
        "\t\t\t\t\t\t\tpadding = 'valid')(inputs)\n",
        "\tx = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\t# Convolution with 3x3 filter followed by ReLU activation\n",
        "\tx = tf.keras.layers.Conv2D(num_filters,\n",
        "\t\t\t\t\t\t\t3,\n",
        "\t\t\t\t\t\t\tpadding = 'valid')(x)\n",
        "\tx = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\t# Max Pooling with 2x2 filter\n",
        "\tx = tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
        "\t\t\t\t\t\t\t\tstrides = 2)(x)\n",
        "\n",
        "\treturn x\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "\n",
        "\t# Upsampling with 2x2 filter\n",
        "\tx = tf.keras.layers.Conv2DTranspose(num_filters,\n",
        "\t\t\t\t\t\t\t\t\t\t(2, 2),\n",
        "\t\t\t\t\t\t\t\t\t\tstrides = 2,\n",
        "\t\t\t\t\t\t\t\t\t\tpadding = 'valid')(inputs)\n",
        "\n",
        "\t# Copy and crop the skip features\n",
        "\t# to match the shape of the upsampled input\n",
        "\tskip_features = tf.image.resize(skip_features,\n",
        "\t\t\t\t\t\t\t\t\tsize = (x.shape[1],\n",
        "\t\t\t\t\t\t\t\t\t\t\tx.shape[2]))\n",
        "\tx = tf.keras.layers.Concatenate()([x, skip_features])\n",
        "\n",
        "\t# Convolution with 3x3 filter followed by ReLU activation\n",
        "\tx = tf.keras.layers.Conv2D(num_filters,\n",
        "\t\t\t\t\t\t\t3,\n",
        "\t\t\t\t\t\t\tpadding = 'valid')(x)\n",
        "\tx = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\t# Convolution with 3x3 filter followed by ReLU activation\n",
        "\tx = tf.keras.layers.Conv2D(num_filters, 3, padding = 'valid')(x)\n",
        "\tx = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\treturn x\n",
        "# Unet code\n",
        "import tensorflow as tf\n",
        "\n",
        "def unet_model(input_shape = (256, 256, 3), num_classes = 1):\n",
        "\tinputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "\t# Contracting Path\n",
        "\ts1 = encoder_block(inputs, 64)\n",
        "\ts2 = encoder_block(s1, 128)\n",
        "\ts3 = encoder_block(s2, 256)\n",
        "\ts4 = encoder_block(s3, 512)\n",
        "\n",
        "\t# Bottleneck\n",
        "\tb1 = tf.keras.layers.Conv2D(1024, 3, padding = 'valid')(s4)\n",
        "\tb1 = tf.keras.layers.Activation('relu')(b1)\n",
        "\tb1 = tf.keras.layers.Conv2D(1024, 3, padding = 'valid')(b1)\n",
        "\tb1 = tf.keras.layers.Activation('relu')(b1)\n",
        "\n",
        "\t# Expansive Path\n",
        "\ts5 = decoder_block(b1, s4, 512)\n",
        "\ts6 = decoder_block(s5, s3, 256)\n",
        "\ts7 = decoder_block(s6, s2, 128)\n",
        "\ts8 = decoder_block(s7, s1, 64)\n",
        "\n",
        "\t# Output\n",
        "\toutputs = tf.keras.layers.Conv2D(num_classes,\n",
        "\t\t\t\t\t\t\t\t\t1,\n",
        "\t\t\t\t\t\t\t\t\tpadding = 'valid',\n",
        "\t\t\t\t\t\t\t\t\tactivation = 'sigmoid')(s8)\n",
        "\n",
        "\tmodel = tf.keras.models.Model(inputs = inputs,\n",
        "\t\t\t\t\t\t\t\toutputs = outputs,\n",
        "\t\t\t\t\t\t\t\tname = 'U-Net')\n",
        "\treturn model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tmodel = unet_model(input_shape=(256, 256, 3), num_classes=2)\n",
        "\tmodel.summary()\n"
      ],
      "metadata": {
        "id": "IO3-4vZSaY4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "0e1212f8-33c9-45bd-dfa8-73531034f209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f672af0e647>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8f672af0e647>\u001b[0m in \u001b[0;36munet_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Expansive Path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0ms5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0ms6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0ms7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8f672af0e647>\u001b[0m in \u001b[0;36mdecoder_block\u001b[0;34m(inputs, skip_features, num_filters)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Copy and crop the skip features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# to match the shape of the upsampled input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \tskip_features = tf.image.resize(skip_features, \n\u001b[0m\u001b[1;32m     31\u001b[0m \t\t\t\t\t\t\t\t\tsize = (x.shape[1], \n\u001b[1;32m     32\u001b[0m \t\t\t\t\t\t\t\t\t\t\tx.shape[2])) \n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fs6hvlVQEuqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}