{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H6DnC4OiqHh",
        "outputId": "46449456-24c7-4866-8694-06e77e7873ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Original MNIST Image:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            " 175  26 166 255 247 127   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            " 225 172 253 242 195  64   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "  93  82  82  56  39   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "  25   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            " 150  27   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            " 253 187   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            " 253 249  64   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            " 250 182   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "  78   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "Output Matrix after ReLU:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 1797, 3330, 4320, 13500, 23962, 35295, 26761, 27974, 38165, 54646, 49608, 27605, 8382, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 2550, 5730, 13174, 23832, 34372, 47048, 56514, 62682, 63114, 69526, 72860, 68028, 61911, 66449, 78480, 65578, 37421, 10066, 0, 0]\n",
            "[0, 0, 0, 0, 0, 4165, 24711, 47835, 63610, 68538, 75059, 80562, 87461, 92059, 101023, 109675, 105548, 79594, 66718, 76078, 88410, 72139, 37562, 9548, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1726, 26550, 64700, 97389, 109907, 118691, 129884, 132183, 130244, 130715, 134926, 115123, 77349, 54871, 56586, 54481, 37203, 16670, 3328, 0, 0]\n",
            "[0, 0, 0, 0, 0, 4139, 32118, 76300, 106369, 121778, 131538, 137094, 116112, 91434, 78092, 93537, 81574, 47990, 17710, 14980, 11645, 5798, 2028, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1494, 19829, 44675, 65752, 81481, 109015, 120593, 96797, 58933, 44943, 50898, 41742, 19616, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 6640, 18924, 25415, 50163, 89305, 119105, 79965, 28332, 4273, 15964, 13632, 8008, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1162, 1119, 15075, 58789, 95422, 83679, 36466, 4712, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 11581, 35669, 78048, 94213, 75327, 41594, 20257, 7217, 66, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 913, 16724, 45545, 78750, 91548, 83724, 63066, 34441, 10125, 1650, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2905, 22917, 47893, 81175, 100512, 99734, 76414, 39344, 13453, 1782, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6723, 26094, 47730, 75586, 97003, 101273, 83678, 43134, 13584, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3735, 18832, 38419, 77789, 108152, 113880, 76768, 32136, 4224, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3910, 16472, 39064, 75998, 116286, 131534, 88870, 38794, 3076, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3315, 16051, 35395, 54888, 69654, 99176, 124247, 134148, 93451, 39336, 3420, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 2040, 11826, 30671, 51591, 73868, 96245, 114394, 125178, 118019, 96383, 56026, 19284, 104, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1955, 7657, 25593, 46690, 70031, 95185, 118812, 129263, 120411, 100693, 81961, 60742, 30056, 9464, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1530, 16137, 35114, 53903, 66272, 88573, 114484, 126648, 119643, 100989, 82602, 63050, 38348, 16316, 4056, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 4675, 19515, 38220, 54717, 72640, 89699, 110492, 127725, 128093, 109098, 86097, 62764, 38742, 16870, 4360, 104, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 11780, 37542, 68074, 98503, 115337, 120715, 115913, 102436, 89579, 68234, 40993, 17313, 4826, 468, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 5109, 27382, 56541, 74244, 78886, 77563, 71122, 66192, 49267, 24179, 7730, 572, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 11288, 31063, 46793, 52877, 49474, 40049, 31970, 18116, 8048, 832, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Pooled Matrix after Max Pooling:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1797, 4320, 23962, 35295, 38165, 54646, 27605, 0]\n",
            "[0, 0, 4165, 47835, 68538, 80562, 92059, 109675, 105548, 76078, 88410, 37562, 0]\n",
            "[0, 0, 4139, 76300, 121778, 137094, 132183, 134926, 115123, 56586, 54481, 16670, 0]\n",
            "[0, 0, 1494, 44675, 81481, 120593, 96797, 50898, 41742, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1162, 15075, 95422, 94213, 41594, 7217, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 913, 45545, 91548, 100512, 76414, 13453, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 6723, 47730, 97003, 113880, 76768, 4224, 0, 0]\n",
            "[0, 0, 0, 0, 0, 16051, 54888, 99176, 134148, 93451, 3420, 0, 0]\n",
            "[0, 0, 0, 7657, 46690, 95185, 129263, 125178, 118019, 56026, 104, 0, 0]\n",
            "[0, 19515, 54717, 89699, 127725, 128093, 119643, 82602, 38348, 4056, 0, 0, 0]\n",
            "[0, 37542, 98503, 120715, 115913, 89579, 40993, 4826, 0, 0, 0, 0, 0]\n",
            "[0, 31063, 52877, 49474, 31970, 8048, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Activation function\n",
        "def relu(matrix):\n",
        "    return [[max(0, val) for val in row] for row in matrix]\n",
        "\n",
        "# Max pooling function\n",
        "def max_pool(matrix, pool_size):\n",
        "    rows = len(matrix)\n",
        "    cols = len(matrix[0])\n",
        "    pooled_rows = rows // pool_size\n",
        "    pooled_cols = cols // pool_size\n",
        "    pooled_matrix = []\n",
        "\n",
        "    for i in range(pooled_rows):\n",
        "        row = []\n",
        "        for j in range(pooled_cols):\n",
        "            block = [matrix[x][y] for x in range(i * pool_size, (i + 1) * pool_size)\n",
        "                     for y in range(j * pool_size, (j + 1) * pool_size)]\n",
        "            row.append(max(block))\n",
        "        pooled_matrix.append(row)\n",
        "\n",
        "    return pooled_matrix\n",
        "\n",
        "# Create a random feature matrix for testing\n",
        "def create_feature_matrix(rows, cols):\n",
        "    feature_matrix = [[random.randint(0, 100) for _ in range(cols)] for _ in range(rows)]\n",
        "    return feature_matrix\n",
        "\n",
        "# Create a random filter matrix\n",
        "def create_filter_matrix(rows, cols):\n",
        "    filter_matrix = [[random.randint(0, 100) for _ in range(cols)] for _ in range(rows)]\n",
        "    return filter_matrix\n",
        "\n",
        "# Apply convolution filter\n",
        "def apply_filter(feature_matrix, filter_matrix, padding=0, stride=1):\n",
        "    # Apply padding to the feature matrix\n",
        "    feature_matrix = np.pad(feature_matrix, ((padding, padding), (padding, padding)), mode='constant').tolist()\n",
        "    output_rows = (len(feature_matrix) - len(filter_matrix)) // stride + 1\n",
        "    output_cols = (len(feature_matrix[0]) - len(filter_matrix[0])) // stride + 1\n",
        "    output_matrix = []\n",
        "\n",
        "    for i in range(0, output_rows, stride):\n",
        "        row = []\n",
        "        for j in range(0, output_cols, stride):\n",
        "            value = 0\n",
        "            for k in range(len(filter_matrix)):\n",
        "                for l in range(len(filter_matrix[0])):\n",
        "                    value += feature_matrix[i + k][j + l] * filter_matrix[k][l]\n",
        "            row.append(value)\n",
        "        output_matrix.append(row)\n",
        "\n",
        "    # Apply ReLU\n",
        "    output_matrix = relu(output_matrix)\n",
        "    return output_matrix\n",
        "\n",
        "# Main function to load MNIST, apply convolution, and max-pooling\n",
        "def main():\n",
        "    # Load MNIST dataset\n",
        "    (x_train, _), (_, _) = mnist.load_data()\n",
        "    # Select a sample image (28x28)\n",
        "    image = x_train[0]\n",
        "    print(\"Original MNIST Image:\")\n",
        "    for row in image:\n",
        "        print(row)\n",
        "\n",
        "    # Convert image to list of lists for compatibility with custom functions\n",
        "    feature_matrix = image.tolist()\n",
        "\n",
        "    # Define filter matrix\n",
        "    filter_rows, filter_cols = 3, 3  # Typical 3x3 filter\n",
        "    filter_matrix = create_filter_matrix(filter_rows, filter_cols)\n",
        "\n",
        "    # Parameters\n",
        "    padding = 0\n",
        "    stride = 1\n",
        "    pool_size = 2\n",
        "\n",
        "    # Apply convolution\n",
        "    output_matrix = apply_filter(feature_matrix, filter_matrix, padding, stride)\n",
        "    print(\"\\nOutput Matrix after ReLU:\")\n",
        "    for row in output_matrix:\n",
        "        print(row)\n",
        "\n",
        "    # Apply max pooling\n",
        "    pooled_matrix = max_pool(output_matrix, pool_size)\n",
        "    print(\"\\nPooled Matrix after Max Pooling:\")\n",
        "    for row in pooled_matrix:\n",
        "        print(row)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Activation function\n",
        "def relu(matrix):\n",
        "    return [[max(0, val) for val in row] for row in matrix]\n",
        "\n",
        "# Max pooling function\n",
        "def max_pool(matrix, pool_size):\n",
        "    rows = len(matrix)\n",
        "    cols = len(matrix[0])\n",
        "    pooled_rows = rows // pool_size\n",
        "    pooled_cols = cols // pool_size\n",
        "    pooled_matrix = []\n",
        "\n",
        "    for i in range(pooled_rows):\n",
        "        row = []\n",
        "        for j in range(pooled_cols):\n",
        "            block = [matrix[x][y] for x in range(i * pool_size, (i + 1) * pool_size)\n",
        "                     for y in range(j * pool_size, (j + 1) * pool_size)]\n",
        "            row.append(max(block))\n",
        "        pooled_matrix.append(row)\n",
        "\n",
        "    return pooled_matrix\n",
        "\n",
        "# Create a random filter matrix\n",
        "def create_filter_matrix(rows, cols):\n",
        "    filter_matrix = [[random.randint(0, 100) for _ in range(cols)] for _ in range(rows)]\n",
        "    return filter_matrix\n",
        "\n",
        "# Apply convolution filter\n",
        "def apply_filter(feature_matrix, filter_matrix, padding=0, stride=1):\n",
        "    # Apply padding to the feature matrix\n",
        "    feature_matrix = np.pad(feature_matrix, ((padding, padding), (padding, padding)), mode='constant').tolist()\n",
        "    output_rows = (len(feature_matrix) - len(filter_matrix)) // stride + 1\n",
        "    output_cols = (len(feature_matrix[0]) - len(filter_matrix[0])) // stride + 1\n",
        "    output_matrix = []\n",
        "\n",
        "    for i in range(0, output_rows, stride):\n",
        "        row = []\n",
        "        for j in range(0, output_cols, stride):\n",
        "            value = 0\n",
        "            for k in range(len(filter_matrix)):\n",
        "                for l in range(len(filter_matrix[0])):\n",
        "                    value += feature_matrix[i + k][j + l] * filter_matrix[k][l]\n",
        "            row.append(value)\n",
        "        output_matrix.append(row)\n",
        "\n",
        "    # Apply ReLU\n",
        "    output_matrix = relu(output_matrix)\n",
        "    return output_matrix\n",
        "\n",
        "# Main function to load MNIST, apply convolution, and max-pooling\n",
        "def main():\n",
        "    # Load MNIST dataset\n",
        "    (x_train, _), (_, _) = mnist.load_data()\n",
        "    # Select a sample image (28x28)\n",
        "    image = x_train[0]\n",
        "\n",
        "    # Convert image to list of lists for compatibility with custom functions\n",
        "    feature_matrix = image.tolist()\n",
        "\n",
        "    # Define filter matrix\n",
        "    filter_rows, filter_cols = 3, 3  # Typical 3x3 filter\n",
        "    filter_matrix = create_filter_matrix(filter_rows, filter_cols)\n",
        "\n",
        "    # Parameters\n",
        "    padding = 1\n",
        "    stride = 1\n",
        "    pool_size = 2\n",
        "\n",
        "    # Apply convolution\n",
        "    output_matrix = apply_filter(feature_matrix, filter_matrix, padding, stride)\n",
        "\n",
        "    # Apply max pooling\n",
        "    pooled_matrix = max_pool(output_matrix, pool_size)\n",
        "\n",
        "    # Convert matrices back to numpy arrays for visualization\n",
        "    original_image = np.array(feature_matrix)\n",
        "    output_image = np.array(output_matrix)\n",
        "    pooled_image = np.array(pooled_matrix)\n",
        "\n",
        "    # Plot the images\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(original_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"After Convolution + ReLU\")\n",
        "    plt.imshow(output_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"After Max Pooling\")\n",
        "    plt.imshow(pooled_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4-RB8Gdfiumj",
        "outputId": "1afbd76e-57d5-4707-c292-f9d2501ae56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tzbMqHWGkAOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}